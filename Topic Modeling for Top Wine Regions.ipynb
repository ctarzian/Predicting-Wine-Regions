{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "018092a2",
   "metadata": {},
   "source": [
    "# Wine Region Topic Modeling\n",
    "### Text Analytics Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1fec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec7ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe9585",
   "metadata": {},
   "source": [
    "## Reading in Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5c98746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris Tarzian\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3106: DtypeWarning: Columns (9,10,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('winemag_fin.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b3e0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1640dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()[['region_1','country','description','points','price']].dropna()\n",
    "df = df.rename(columns = {'region_1': 'region'})                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6572494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Napa Valley                8285\n",
       "Columbia Valley (WA)       7094\n",
       "Russian River Valley       5142\n",
       "California                 4692\n",
       "Mendoza                    4307\n",
       "Paso Robles                4000\n",
       "Willamette Valley          3372\n",
       "Alsace                     2712\n",
       "Rioja                      2578\n",
       "Finger Lakes               2350\n",
       "Sonoma Coast               2344\n",
       "Sonoma County              2317\n",
       "Champagne                  2015\n",
       "Toscana                    1990\n",
       "Brunello di Montalcino     1985\n",
       "Carneros                   1834\n",
       "Barolo                     1818\n",
       "Dry Creek Valley           1759\n",
       "Walla Walla Valley (WA)    1750\n",
       "Santa Barbara County       1732\n",
       "Yakima Valley              1672\n",
       "Sicilia                    1644\n",
       "Sta. Rita Hills            1538\n",
       "Alexander Valley           1444\n",
       "Chianti Classico           1418\n",
       "Lodi                       1368\n",
       "Santa Lucia Highlands      1354\n",
       "Santa Ynez Valley          1327\n",
       "Central Coast              1299\n",
       "Ribera del Duero           1228\n",
       "Name: region, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.region.value_counts().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce627295",
   "metadata": {},
   "source": [
    "## Removing Outliers and Grouping Data by Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c6b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = np.percentile(df['price'], 10,\n",
    "                   interpolation = 'midpoint')\n",
    " \n",
    "Q3 = np.percentile(df['price'], 90,\n",
    "                   interpolation = 'midpoint')\n",
    "IQR = Q3 - Q1\n",
    "df = df[df.price < (Q3+1.5*IQR)+1]\n",
    "\n",
    "Q1 = np.percentile(df['points'], 5, interpolation = 'midpoint')#\n",
    " \n",
    "Q3 = np.percentile(df['points'], 95, interpolation = 'midpoint')\n",
    "IQR = Q3 - Q1\n",
    "df = df[df.points < (Q3+1.5*IQR)+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa308ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(df.region.value_counts())\n",
    "data1.columns = ['counts']\n",
    "df = df.groupby('region').agg({'country':'first','description':lambda x: ' '.join(x), \n",
    "                         'points':'mean', \n",
    "                         'price':'mean'})\n",
    "df = df.join(data1)\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5031ea3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>US</td>\n",
       "      <td>Soft, supple plum envelopes an oaky structure ...</td>\n",
       "      <td>88.632009</td>\n",
       "      <td>46.891501</td>\n",
       "      <td>7954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Columbia Valley (WA)</td>\n",
       "      <td>US</td>\n",
       "      <td>Aromas of cranberry, barrel spice and herb are...</td>\n",
       "      <td>88.680671</td>\n",
       "      <td>27.620753</td>\n",
       "      <td>7093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>Russian River Valley</td>\n",
       "      <td>US</td>\n",
       "      <td>This wine is put together from multiple vineya...</td>\n",
       "      <td>89.274407</td>\n",
       "      <td>39.859588</td>\n",
       "      <td>5142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>Very deep in color and spicy-smoky in flavor, ...</td>\n",
       "      <td>85.222341</td>\n",
       "      <td>15.392027</td>\n",
       "      <td>4691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>Mendoza</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Raw black-cherry aromas are direct and simple ...</td>\n",
       "      <td>86.184315</td>\n",
       "      <td>20.896672</td>\n",
       "      <td>4297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>Paso Robles</td>\n",
       "      <td>US</td>\n",
       "      <td>This wine from the Geneseo district offers aro...</td>\n",
       "      <td>87.172966</td>\n",
       "      <td>32.451314</td>\n",
       "      <td>3995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>88.927003</td>\n",
       "      <td>34.321068</td>\n",
       "      <td>3370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Alsace</td>\n",
       "      <td>France</td>\n",
       "      <td>This dry and restrained wine offers spice in p...</td>\n",
       "      <td>89.563031</td>\n",
       "      <td>31.750832</td>\n",
       "      <td>2705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Rioja</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Slightly foxy on the nose, with rubbery aromas...</td>\n",
       "      <td>87.306342</td>\n",
       "      <td>27.596729</td>\n",
       "      <td>2507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Finger Lakes</td>\n",
       "      <td>US</td>\n",
       "      <td>A wisp of bramble extends a savory tone from n...</td>\n",
       "      <td>86.866809</td>\n",
       "      <td>20.109362</td>\n",
       "      <td>2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>Sonoma Coast</td>\n",
       "      <td>US</td>\n",
       "      <td>Oak and earth intermingle around robust aromas...</td>\n",
       "      <td>89.872168</td>\n",
       "      <td>45.897392</td>\n",
       "      <td>2339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Sonoma County</td>\n",
       "      <td>US</td>\n",
       "      <td>This blend of Sangiovese, Malbec, Cabernet Sau...</td>\n",
       "      <td>87.015625</td>\n",
       "      <td>27.691406</td>\n",
       "      <td>2304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Brunello di Montalcino</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Black-skinned berry, pipe tobacco and Mediterr...</td>\n",
       "      <td>90.770647</td>\n",
       "      <td>67.709627</td>\n",
       "      <td>1901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>Toscana</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Made primarily from Sangiovese, with some Malv...</td>\n",
       "      <td>89.220447</td>\n",
       "      <td>43.865815</td>\n",
       "      <td>1878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Carneros</td>\n",
       "      <td>US</td>\n",
       "      <td>Fine acidity and a bracing minerality, like a ...</td>\n",
       "      <td>88.477644</td>\n",
       "      <td>36.934024</td>\n",
       "      <td>1834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Champagne</td>\n",
       "      <td>France</td>\n",
       "      <td>This fat, yeasty Champagne is comprised predom...</td>\n",
       "      <td>89.924932</td>\n",
       "      <td>64.240000</td>\n",
       "      <td>1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Dry Creek Valley</td>\n",
       "      <td>US</td>\n",
       "      <td>Rustic and dry, this has flavors of berries, c...</td>\n",
       "      <td>87.528709</td>\n",
       "      <td>29.948835</td>\n",
       "      <td>1759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>Walla Walla Valley (WA)</td>\n",
       "      <td>US</td>\n",
       "      <td>The light aromas suggest notes of star fruit a...</td>\n",
       "      <td>90.283257</td>\n",
       "      <td>42.331422</td>\n",
       "      <td>1744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Barolo</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Slightly backward, particularly given the vint...</td>\n",
       "      <td>90.729466</td>\n",
       "      <td>69.121195</td>\n",
       "      <td>1741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Santa Barbara County</td>\n",
       "      <td>US</td>\n",
       "      <td>Overly sweet and simple, and something of a di...</td>\n",
       "      <td>87.899538</td>\n",
       "      <td>29.823326</td>\n",
       "      <td>1732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       region    country  \\\n",
       "767               Napa Valley         US   \n",
       "292      Columbia Valley (WA)         US   \n",
       "938      Russian River Valley         US   \n",
       "164                California         US   \n",
       "657                   Mendoza  Argentina   \n",
       "822               Paso Robles         US   \n",
       "1273        Willamette Valley         US   \n",
       "23                     Alsace     France   \n",
       "907                     Rioja      Spain   \n",
       "453              Finger Lakes         US   \n",
       "1040             Sonoma Coast         US   \n",
       "1041            Sonoma County         US   \n",
       "146    Brunello di Montalcino      Italy   \n",
       "1117                  Toscana      Italy   \n",
       "181                  Carneros         US   \n",
       "207                 Champagne     France   \n",
       "416          Dry Creek Valley         US   \n",
       "1268  Walla Walla Valley (WA)         US   \n",
       "84                     Barolo      Italy   \n",
       "994      Santa Barbara County         US   \n",
       "\n",
       "                                            description     points      price  \\\n",
       "767   Soft, supple plum envelopes an oaky structure ...  88.632009  46.891501   \n",
       "292   Aromas of cranberry, barrel spice and herb are...  88.680671  27.620753   \n",
       "938   This wine is put together from multiple vineya...  89.274407  39.859588   \n",
       "164   Very deep in color and spicy-smoky in flavor, ...  85.222341  15.392027   \n",
       "657   Raw black-cherry aromas are direct and simple ...  86.184315  20.896672   \n",
       "822   This wine from the Geneseo district offers aro...  87.172966  32.451314   \n",
       "1273  Tart and snappy, the flavors of lime flesh and...  88.927003  34.321068   \n",
       "23    This dry and restrained wine offers spice in p...  89.563031  31.750832   \n",
       "907   Slightly foxy on the nose, with rubbery aromas...  87.306342  27.596729   \n",
       "453   A wisp of bramble extends a savory tone from n...  86.866809  20.109362   \n",
       "1040  Oak and earth intermingle around robust aromas...  89.872168  45.897392   \n",
       "1041  This blend of Sangiovese, Malbec, Cabernet Sau...  87.015625  27.691406   \n",
       "146   Black-skinned berry, pipe tobacco and Mediterr...  90.770647  67.709627   \n",
       "1117  Made primarily from Sangiovese, with some Malv...  89.220447  43.865815   \n",
       "181   Fine acidity and a bracing minerality, like a ...  88.477644  36.934024   \n",
       "207   This fat, yeasty Champagne is comprised predom...  89.924932  64.240000   \n",
       "416   Rustic and dry, this has flavors of berries, c...  87.528709  29.948835   \n",
       "1268  The light aromas suggest notes of star fruit a...  90.283257  42.331422   \n",
       "84    Slightly backward, particularly given the vint...  90.729466  69.121195   \n",
       "994   Overly sweet and simple, and something of a di...  87.899538  29.823326   \n",
       "\n",
       "      counts  \n",
       "767     7954  \n",
       "292     7093  \n",
       "938     5142  \n",
       "164     4691  \n",
       "657     4297  \n",
       "822     3995  \n",
       "1273    3370  \n",
       "23      2705  \n",
       "907     2507  \n",
       "453     2350  \n",
       "1040    2339  \n",
       "1041    2304  \n",
       "146     1901  \n",
       "1117    1878  \n",
       "181     1834  \n",
       "207     1825  \n",
       "416     1759  \n",
       "1268    1744  \n",
       "84      1741  \n",
       "994     1732  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_filter = df['counts'] > 1000\n",
    "df = df[counts_filter]\n",
    "df.sort_values(by='counts', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43f7c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "napa_filter = df['region'] == 'Napa Valley'\n",
    "napa = df[napa_filter]\n",
    "napa_docs = napa['description'].tolist()\n",
    "\n",
    "willanmetteValley_filter = df['region'] == 'Willamette Valley'\n",
    "willanmetteValley = df[willanmetteValley_filter]\n",
    "willanmetteValley_docs = willanmetteValley['description'].tolist()\n",
    "\n",
    "fingerlakes_filter = df['region'] == 'Finger Lakes'\n",
    "fingerlakes = df[fingerlakes_filter]\n",
    "fingerlakes_docs = fingerlakes['description'].tolist()\n",
    "\n",
    "alsace_filter = df['region'] == 'Alsace'\n",
    "alsace = df[alsace_filter]\n",
    "alsace_docs = alsace['description'].tolist()\n",
    "\n",
    "mendoza_filter = df['region'] == 'Mendoza'\n",
    "mendoza = df[mendoza_filter]\n",
    "mendoza_docs = mendoza['description'].tolist()\n",
    "\n",
    "columbiaValley_filter = df['region'] == 'Columbia Valley (WA)'\n",
    "columbiaValley = df[columbiaValley_filter]\n",
    "columbiaValley_docs = columbiaValley['description'].tolist()\n",
    "\n",
    "toscana_filter = df['region'] == 'Toscana'\n",
    "toscana = df[toscana_filter]\n",
    "toscana_docs = toscana['description'].tolist()\n",
    "\n",
    "rioja_filter = df['region'] == 'Rioja'\n",
    "rioja = df[rioja_filter]\n",
    "rioja_docs = rioja['description'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601f03a3",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60506595",
   "metadata": {},
   "source": [
    "## Napa Valley (CA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cce1c6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import gensim'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTop 10 words for Napa Valley (CA)\u001b[0m\n",
      "\"flavor\", \"tannin\", \"blackberry\", \"oak\", \"cabernet\", \"dry\", \"black\", \"rich\", \"currant\", \"finish\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the documents.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['flavor','wine','cherry', 'fruit'])\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(napa_docs)):\n",
    "    napa_docs[idx] = napa_docs[idx].lower()  # Convert to lowercase.\n",
    "    napa_docs[idx] = tokenizer.tokenize(napa_docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "napa_docs = [[token for token in doc if not token.isnumeric()] for doc in napa_docs]\n",
    "    \n",
    "# Remove stopwords.\n",
    "napa_docs = [[token for token in doc if token not in stop_words] for doc in napa_docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "napa_docs = [[token for token in doc if len(token) > 1] for doc in napa_docs]\n",
    "\n",
    "# Lemmatize the documents.\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "napa_docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in napa_docs]\n",
    "\n",
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(napa_docs, min_count=10)\n",
    "for idx in range(len(napa_docs)):\n",
    "    for token in bigram[napa_docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            napa_docs[idx].append(token)\n",
    "            \n",
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(napa_docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in napa_docs]\n",
    "\n",
    "sort_token = sorted(dictionary.items(),key=lambda k:k[0], reverse = False)\n",
    "unique_token = [token for (ID,token) in sort_token]\n",
    "\n",
    "import numpy as np\n",
    "matrix = gensim.matutils.corpus2dense(corpus,num_terms=len(dictionary),dtype = 'int')\n",
    "matrix = matrix.T #transpose the matrix \n",
    "\n",
    "#convert the numpy matrix into pandas data frame\n",
    "matrix_df = pd.DataFrame(matrix, columns=unique_token)\n",
    "\n",
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 1\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 100\n",
    "eval_every = 1  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "lda = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "\n",
    "lda.print_topics(1) #V matrix, topic matrix\n",
    "import re\n",
    "for i,topic in lda.print_topics(1):\n",
    "    print(color.BOLD + (f'Top 10 words for Napa Valley (CA)') + color.END)\n",
    "    print(\", \".join(re.findall('\".*?\"',topic)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61cb0bc",
   "metadata": {},
   "source": [
    "## Willamette Valley (OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2cc13dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import gensim'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTop 10 words for Willamette Valley (OR)\u001b[0m\n",
      "\"flavor\", \"pinot\", \"light\", \"tart\", \"vineyard\", \"oak\", \"apple\", \"hint\", \"tannin\", \"barrel\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the documents.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['wine', 'flavor', 'fruit', 'cherry','finish'])\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(willanmetteValley_docs)):\n",
    "    willanmetteValley_docs[idx] = willanmetteValley_docs[idx].lower()  # Convert to lowercase.\n",
    "    willanmetteValley_docs[idx] = tokenizer.tokenize(willanmetteValley_docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "willanmetteValley_docs = [[token for token in doc if not token.isnumeric()] for doc in willanmetteValley_docs]\n",
    "    \n",
    "# Remove stopwords.\n",
    "willanmetteValley_docs = [[token for token in doc if token not in stop_words] for doc in willanmetteValley_docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "willanmetteValley_docs = [[token for token in doc if len(token) > 1] for doc in willanmetteValley_docs]\n",
    "\n",
    "# Lemmatize the documents.\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "willanmetteValley_docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in willanmetteValley_docs]\n",
    "\n",
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(willanmetteValley_docs, min_count=10)\n",
    "for idx in range(len(willanmetteValley_docs)):\n",
    "    for token in bigram[willanmetteValley_docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            willanmetteValley_docs[idx].append(token)\n",
    "            \n",
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary1 = Dictionary(willanmetteValley_docs)\n",
    "corpus1 = [dictionary1.doc2bow(doc) for doc in willanmetteValley_docs]\n",
    "\n",
    "sort_token1 = sorted(dictionary1.items(),key=lambda k:k[0], reverse = False)\n",
    "unique_token1 = [token.encode('utf8') for (ID,token) in sort_token1]\n",
    "\n",
    "import numpy as np\n",
    "matrix1 = gensim.matutils.corpus2dense(corpus1,num_terms=len(dictionary1),dtype = 'int')\n",
    "matrix1 = matrix1.T #transpose the matrix \n",
    "\n",
    "#convert the numpy matrix into pandas data frame\n",
    "matrix_df1 = pd.DataFrame(matrix1, columns=unique_token1)\n",
    "\n",
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 1\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 100\n",
    "eval_every = 1  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary1[0]  # This is only to \"load\" the dictionary.\n",
    "id2word1 = dictionary1.id2token\n",
    "\n",
    "lda = LdaModel(\n",
    "    corpus=corpus1,\n",
    "    id2word=id2word1,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "\n",
    "lda.print_topics(1) #V matrix, topic matrix\n",
    "import re\n",
    "for i,topic in lda.print_topics(1):\n",
    "    print(color.BOLD + (f'Top 10 words for Willamette Valley (OR)') + color.END)\n",
    "    print(\", \".join(re.findall('\".*?\"',topic)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6023b5c0",
   "metadata": {},
   "source": [
    "## Columbia Valley (Washington)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c1cbad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import gensim'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTop 10 words for Columbia Valley (WA)\u001b[0m\n",
      "\"flavor\", \"aroma\", \"cabernet\", \"blend\", \"tannin\", \"herb\", \"black\", \"spice\", \"merlot\", \"red\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the documents.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['wine', 'flavor', 'fruit', 'cherry','finish'])\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(columbiaValley_docs)):\n",
    "    columbiaValley_docs[idx] = columbiaValley_docs[idx].lower()  # Convert to lowercase.\n",
    "    columbiaValley_docs[idx] = tokenizer.tokenize(columbiaValley_docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "columbiaValley_docs = [[token for token in doc if not token.isnumeric()] for doc in columbiaValley_docs]\n",
    "    \n",
    "# Remove stopwords.\n",
    "columbiaValley_docs = [[token for token in doc if token not in stop_words] for doc in columbiaValley_docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "columbiaValley_docs = [[token for token in doc if len(token) > 1] for doc in columbiaValley_docs]\n",
    "\n",
    "# Lemmatize the documents.\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "columbiaValley_docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in columbiaValley_docs]\n",
    "\n",
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(columbiaValley_docs, min_count=10)\n",
    "for idx in range(len(columbiaValley_docs)):\n",
    "    for token in bigram[columbiaValley_docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            columbiaValley_docs[idx].append(token)\n",
    "            \n",
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary6 = Dictionary(columbiaValley_docs)\n",
    "corpus6 = [dictionary6.doc2bow(doc) for doc in columbiaValley_docs]\n",
    "\n",
    "sort_token6 = sorted(dictionary6.items(),key=lambda k:k[0], reverse = False)\n",
    "unique_token6 = [token.encode('utf8') for (ID,token) in sort_token6]\n",
    "\n",
    "import numpy as np\n",
    "matrix6 = gensim.matutils.corpus2dense(corpus6,num_terms=len(dictionary6),dtype = 'int')\n",
    "matrix6 = matrix6.T #transpose the matrix \n",
    "\n",
    "#convert the numpy matrix into pandas data frame\n",
    "matrix_df6 = pd.DataFrame(matrix6, columns=unique_token6)\n",
    "\n",
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 1\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 100\n",
    "eval_every = 1  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary6[0]  # This is only to \"load\" the dictionary.\n",
    "id2word6 = dictionary6.id2token\n",
    "\n",
    "lda = LdaModel(\n",
    "    corpus=corpus6,\n",
    "    id2word=id2word6,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "\n",
    "lda.print_topics(1) #V matrix, topic matrix\n",
    "import re\n",
    "for i,topic in lda.print_topics(1):\n",
    "    print(color.BOLD + (f'Top 10 words for Columbia Valley (WA)') + color.END)\n",
    "    print(\", \".join(re.findall('\".*?\"',topic)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac4ee9b",
   "metadata": {},
   "source": [
    "## Finger Lakes (NY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b034785b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import gensim'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTop 10 words for Finger Lakes (NY)\u001b[0m\n",
      "\"finish\", \"palate\", \"flavor\", \"acidity\", \"note\", \"dry\", \"apple\", \"cherry\", \"fresh\", \"riesling\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the documents.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['flavor', 'wine'])\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(fingerlakes_docs)):\n",
    "    fingerlakes_docs[idx] = fingerlakes_docs[idx].lower()  # Convert to lowercase.\n",
    "    fingerlakes_docs[idx] = tokenizer.tokenize(fingerlakes_docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "fingerlakes_docs = [[token for token in doc if not token.isnumeric()] for doc in fingerlakes_docs]\n",
    "    \n",
    "# Remove stopwords.\n",
    "fingerlakes_docs = [[token for token in doc if token not in stop_words] for doc in fingerlakes_docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "fingerlakes_docs = [[token for token in doc if len(token) > 1] for doc in fingerlakes_docs]\n",
    "\n",
    "# Lemmatize the documents.\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "fingerlakes_docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in fingerlakes_docs]\n",
    "\n",
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(fingerlakes_docs, min_count=10)\n",
    "for idx in range(len(fingerlakes_docs)):\n",
    "    for token in bigram[fingerlakes_docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            fingerlakes_docs[idx].append(token)\n",
    "            \n",
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary2 = Dictionary(fingerlakes_docs)\n",
    "corpus2 = [dictionary2.doc2bow(doc) for doc in fingerlakes_docs]\n",
    "\n",
    "sort_token2 = sorted(dictionary2.items(),key=lambda k:k[0], reverse = False)\n",
    "unique_token2 = [token.encode('utf8') for (ID,token) in sort_token2]\n",
    "\n",
    "import numpy as np\n",
    "matrix2 = gensim.matutils.corpus2dense(corpus2,num_terms=len(dictionary2),dtype = 'int')\n",
    "matrix2 = matrix2.T #transpose the matrix \n",
    "\n",
    "#convert the numpy matrix into pandas data frame\n",
    "matrix_df2 = pd.DataFrame(matrix2, columns=unique_token2)\n",
    "\n",
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 1\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 100\n",
    "eval_every = 1  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary2[0]  # This is only to \"load\" the dictionary.\n",
    "id2word2 = dictionary2.id2token\n",
    "\n",
    "lda = LdaModel(\n",
    "    corpus=corpus2,\n",
    "    id2word=id2word2,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "\n",
    "lda.print_topics(1) #V matrix, topic matrix\n",
    "import re\n",
    "for i,topic in lda.print_topics(1):\n",
    "    print(color.BOLD + (f'Top 10 words for Finger Lakes (NY)') + color.END)\n",
    "    print(\", \".join(re.findall('\".*?\"',topic)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bfe51f",
   "metadata": {},
   "source": [
    "## Toscana (Italy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7a66107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import gensim'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTop 10 words for Toscana (Italy)\u001b[0m\n",
      "\"aroma\", \"black\", \"tannin\", \"cabernet\", \"blend\", \"sangiovese\", \"palate\", \"spice\", \"merlot\", \"sauvignon\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the documents.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['wine', 'flavor','fruit', 'cherry'])\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(toscana_docs)):\n",
    "    toscana_docs[idx] = toscana_docs[idx].lower()  # Convert to lowercase.\n",
    "    toscana_docs[idx] = tokenizer.tokenize(toscana_docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "toscana_docs = [[token for token in doc if not token.isnumeric()] for doc in toscana_docs]\n",
    "    \n",
    "# Remove stopwords.\n",
    "toscana_docs = [[token for token in doc if token not in stop_words] for doc in toscana_docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "toscana_docs = [[token for token in doc if len(token) > 1] for doc in toscana_docs]\n",
    "\n",
    "# Lemmatize the documents.\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "toscana_docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in toscana_docs]\n",
    "\n",
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(toscana_docs, min_count=10)\n",
    "for idx in range(len(toscana_docs)):\n",
    "    for token in bigram[toscana_docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            toscana_docs[idx].append(token)\n",
    "            \n",
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary3 = Dictionary(toscana_docs)\n",
    "corpus3 = [dictionary3.doc2bow(doc) for doc in toscana_docs]\n",
    "\n",
    "sort_token3 = sorted(dictionary3.items(),key=lambda k:k[0], reverse = False)\n",
    "unique_token3 = [token.encode('utf8') for (ID,token) in sort_token3]\n",
    "\n",
    "import numpy as np\n",
    "matrix3 = gensim.matutils.corpus2dense(corpus3,num_terms=len(dictionary3),dtype = 'int')\n",
    "matrix3 = matrix3.T #transpose the matrix \n",
    "\n",
    "#convert the numpy matrix into pandas data frame\n",
    "matrix_df3 = pd.DataFrame(matrix3, columns=unique_token3)\n",
    "\n",
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 1\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 100\n",
    "eval_every = 1  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary3[0]  # This is only to \"load\" the dictionary.\n",
    "id2word3 = dictionary3.id2token\n",
    "\n",
    "lda = LdaModel(\n",
    "    corpus=corpus3,\n",
    "    id2word=id2word3,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "\n",
    "lda.print_topics(1) #V matrix, topic matrix\n",
    "import re\n",
    "for i,topic in lda.print_topics(1):\n",
    "    print(color.BOLD + (f'Top 10 words for Toscana (Italy)') + color.END)\n",
    "    print(\", \".join(re.findall('\".*?\"',topic)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5180c5",
   "metadata": {},
   "source": [
    "## Alsace (France)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2e9a884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import gensim'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTop 10 words for Alsace (France)\u001b[0m\n",
      "\"palate\", \"dry\", \"drink\", \"note\", \"nose\", \"ripe\", \"apple\", \"freshness\", \"fresh\", \"flavor\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the documents.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['wine', 'flavor','fruit', 'cherry','finish'])\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(alsace_docs)):\n",
    "    alsace_docs[idx] = alsace_docs[idx].lower()  # Convert to lowercase.\n",
    "    alsace_docs[idx] = tokenizer.tokenize(alsace_docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "alsace_docs = [[token for token in doc if not token.isnumeric()] for doc in alsace_docs]\n",
    "    \n",
    "# Remove stopwords.\n",
    "alsace_docs = [[token for token in doc if token not in stop_words] for doc in alsace_docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "alsace_docs = [[token for token in doc if len(token) > 1] for doc in alsace_docs]\n",
    "\n",
    "# Lemmatize the documents.\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "alsace_docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in alsace_docs]\n",
    "\n",
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(alsace_docs, min_count=10)\n",
    "for idx in range(len(alsace_docs)):\n",
    "    for token in bigram[alsace_docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            alsace_docs[idx].append(token)\n",
    "            \n",
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary4 = Dictionary(alsace_docs)\n",
    "corpus4 = [dictionary4.doc2bow(doc) for doc in alsace_docs]\n",
    "\n",
    "sort_token4 = sorted(dictionary4.items(),key=lambda k:k[0], reverse = False)\n",
    "unique_token4 = [token.encode('utf8') for (ID,token) in sort_token4]\n",
    "\n",
    "import numpy as np\n",
    "matrix4 = gensim.matutils.corpus2dense(corpus4,num_terms=len(dictionary4),dtype = 'int')\n",
    "matrix4 = matrix4.T #transpose the matrix \n",
    "\n",
    "#convert the numpy matrix into pandas data frame\n",
    "matrix_df4 = pd.DataFrame(matrix4, columns=unique_token4)\n",
    "\n",
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 1\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 100\n",
    "eval_every = 1  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary4[0]  # This is only to \"load\" the dictionary.\n",
    "id2word4 = dictionary4.id2token\n",
    "\n",
    "lda = LdaModel(\n",
    "    corpus=corpus4,\n",
    "    id2word=id2word4,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "\n",
    "lda.print_topics(1) #V matrix, topic matrix\n",
    "import re\n",
    "for i,topic in lda.print_topics(1):\n",
    "    print(color.BOLD + (f'Top 10 words for Alsace (France)') + color.END)\n",
    "    print(\", \".join(re.findall('\".*?\"',topic)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0639e8ef",
   "metadata": {},
   "source": [
    "## Mendoza (Argentina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0263c9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import gensim'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTop 10 words for Mendoza (Argentina)\u001b[0m\n",
      "\"flavor\", \"aroma\", \"palate\", \"berry\", \"plum\", \"feel\", \"nose\", \"black\", \"blackberry\", \"note\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tokenize the documents.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['wine', 'flavor','fruit', 'cherry','finish'])\n",
    "\n",
    "#Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(mendoza_docs)):\n",
    "    mendoza_docs[idx] = mendoza_docs[idx].lower()  # Convert to lowercase.\n",
    "    mendoza_docs[idx] = tokenizer.tokenize(mendoza_docs[idx])  # Split into words.\n",
    "\n",
    "#Remove numbers, but not words that contain numbers.\n",
    "mendoza_docs = [[token for token in doc if not token.isnumeric()] for doc in mendoza_docs]\n",
    "    \n",
    "#Remove stopwords.\n",
    "mendoza_docs = [[token for token in doc if token not in stop_words] for doc in mendoza_docs]\n",
    "\n",
    "#Remove words that are only one character.\n",
    "mendoza_docs = [[token for token in doc if len(token) > 1] for doc in mendoza_docs]\n",
    "\n",
    "# Lemmatize the documents.\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "mendoza_docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in mendoza_docs]\n",
    "\n",
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(mendoza_docs, min_count=10)\n",
    "for idx in range(len(mendoza_docs)):\n",
    "    for token in bigram[mendoza_docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            mendoza_docs[idx].append(token)\n",
    "            \n",
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary5 = Dictionary(mendoza_docs)\n",
    "corpus5 = [dictionary5.doc2bow(doc) for doc in mendoza_docs]\n",
    "\n",
    "sort_token5 = sorted(dictionary5.items(),key=lambda k:k[0], reverse = False)\n",
    "unique_token5 = [token.encode('utf8') for (ID,token) in sort_token5]\n",
    "\n",
    "import numpy as np\n",
    "matrix5 = gensim.matutils.corpus2dense(corpus5,num_terms=len(dictionary5),dtype = 'int')\n",
    "matrix5 = matrix5.T #transpose the matrix \n",
    "\n",
    "#convert the numpy matrix into pandas data frame\n",
    "matrix_df5 = pd.DataFrame(matrix5, columns=unique_token5)\n",
    "\n",
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 1\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 100\n",
    "eval_every = 1  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary5[0]  # This is only to \"load\" the dictionary.\n",
    "id2word5 = dictionary5.id2token\n",
    "\n",
    "lda = LdaModel(\n",
    "    corpus=corpus5,\n",
    "    id2word=id2word5,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "\n",
    "lda.print_topics(1) #V matrix, topic matrix\n",
    "import re\n",
    "for i,topic in lda.print_topics(1):\n",
    "    print(color.BOLD + (f'Top 10 words for Mendoza (Argentina)') + color.END)\n",
    "    print(\", \".join(re.findall('\".*?\"',topic)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8266b4",
   "metadata": {},
   "source": [
    "### Rioja (Spain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f87432b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import gensim'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTop 10 words for Rioja (Spain)\u001b[0m\n",
      "\"flavor\", \"aroma\", \"berry\", \"plum\", \"palate\", \"feel\", \"drink\", \"oak\", \"red\", \"note\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tokenize the documents.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['wine', 'flavor','fruit', 'cherry','finish'])\n",
    "\n",
    "#Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(rioja_docs)):\n",
    "    rioja_docs[idx] = rioja_docs[idx].lower()  # Convert to lowercase.\n",
    "    rioja_docs[idx] = tokenizer.tokenize(rioja_docs[idx])  # Split into words.\n",
    "\n",
    "#Remove numbers, but not words that contain numbers.\n",
    "rioja_docs = [[token for token in doc if not token.isnumeric()] for doc in rioja_docs]\n",
    "    \n",
    "#Remove stopwords.\n",
    "rioja_docs = [[token for token in doc if token not in stop_words] for doc in rioja_docs]\n",
    "\n",
    "#Remove words that are only one character.\n",
    "rioja_docs = [[token for token in doc if len(token) > 1] for doc in rioja_docs]\n",
    "\n",
    "rioja# Lemmatize the documents.\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "rioja_docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in rioja_docs]\n",
    "\n",
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(rioja_docs, min_count=10)\n",
    "for idx in range(len(rioja_docs)):\n",
    "    for token in bigram[rioja_docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            rioja_docs[idx].append(token)\n",
    "            \n",
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary7 = Dictionary(rioja_docs)\n",
    "corpus7 = [dictionary7.doc2bow(doc) for doc in rioja_docs]\n",
    "\n",
    "sort_token7 = sorted(dictionary7.items(),key=lambda k:k[0], reverse = False)\n",
    "unique_token7 = [token.encode('utf8') for (ID,token) in sort_token7]\n",
    "\n",
    "import numpy as np\n",
    "matrix7 = gensim.matutils.corpus2dense(corpus7,num_terms=len(dictionary7),dtype = 'int')\n",
    "matrix7 = matrix7.T #transpose the matrix \n",
    "\n",
    "#convert the numpy matrix into pandas data frame\n",
    "matrix_df7 = pd.DataFrame(matrix7, columns=unique_token7)\n",
    "\n",
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 1\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 100\n",
    "eval_every = 1  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary5[0]  # This is only to \"load\" the dictionary.\n",
    "id2word7 = dictionary7.id2token\n",
    "\n",
    "lda = LdaModel(\n",
    "    corpus=corpus7,\n",
    "    id2word=id2word7,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "\n",
    "lda.print_topics(1) #V matrix, topic matrix\n",
    "import re\n",
    "for i,topic in lda.print_topics(1):\n",
    "    print(color.BOLD + (f'Top 10 words for Rioja (Spain)') + color.END)\n",
    "    print(\", \".join(re.findall('\".*?\"',topic)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119b6384",
   "metadata": {},
   "source": [
    "## Best Bang for your Buck Wineries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1464c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8126d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop_duplicates()[['winery','region_1','country','points','price']].dropna()\n",
    "df = df2.rename(columns = {'region_1': 'region'})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7dd5e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"region\"]=='Finger Lakes') | (df[\"region\"]=='Alsace')  | (df[\"region\"]=='Rioja') | (df[\"region\"]=='Willamette Valley') | (df[\"region\"]=='Mendoza') | (df[\"region\"]=='Columbia Valley (WA)') | (df[\"region\"]=='Toscana') | (df[\"region\"]=='Napa Valley')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d22d76ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winery</th>\n",
       "      <th>region</th>\n",
       "      <th>country</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rainstorm</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>US</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sweet Cheeks</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>US</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trimbach</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>France</td>\n",
       "      <td>87</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jean-Baptiste Adam</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>France</td>\n",
       "      <td>87</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kirkland Signature</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>US</td>\n",
       "      <td>87</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149617</th>\n",
       "      <td>Standing Stone</td>\n",
       "      <td>Finger Lakes</td>\n",
       "      <td>US</td>\n",
       "      <td>84</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149626</th>\n",
       "      <td>Beringer</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>US</td>\n",
       "      <td>84</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149627</th>\n",
       "      <td>Marc Kreydenweiss</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>France</td>\n",
       "      <td>84</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149630</th>\n",
       "      <td>Pine Ridge</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>US</td>\n",
       "      <td>84</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149634</th>\n",
       "      <td>W. Gisselbrecht</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>France</td>\n",
       "      <td>84</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32688 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    winery             region country  points  price\n",
       "2                Rainstorm  Willamette Valley      US      87   14.0\n",
       "4             Sweet Cheeks  Willamette Valley      US      87   65.0\n",
       "7                 Trimbach             Alsace  France      87   24.0\n",
       "9       Jean-Baptiste Adam             Alsace  France      87   27.0\n",
       "10      Kirkland Signature        Napa Valley      US      87   19.0\n",
       "...                    ...                ...     ...     ...    ...\n",
       "149617      Standing Stone       Finger Lakes      US      84   13.0\n",
       "149626            Beringer        Napa Valley      US      84   16.0\n",
       "149627   Marc Kreydenweiss             Alsace  France      84   21.0\n",
       "149630          Pine Ridge        Napa Valley      US      84   27.0\n",
       "149634     W. Gisselbrecht             Alsace  France      84   15.0\n",
       "\n",
       "[32688 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46a93f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = np.percentile(df['price'], 10,\n",
    "                   interpolation = 'midpoint')\n",
    " \n",
    "Q3 = np.percentile(df['price'], 90,\n",
    "                   interpolation = 'midpoint')\n",
    "IQR = Q3 - Q1\n",
    "df = df[df.price < (Q3+1.5*IQR)+1]\n",
    "\n",
    "Q1 = np.percentile(df['points'], 5, interpolation = 'midpoint')#\n",
    " \n",
    "Q3 = np.percentile(df['points'], 95, interpolation = 'midpoint')\n",
    "IQR = Q3 - Q1\n",
    "df = df[df.points < (Q3+1.5*IQR)+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3d41635",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = df.groupby('winery').agg({'region':'first','country':'first',\n",
    "                         'points':'mean', \n",
    "                         'price':'mean'})\n",
    "df2 = wine\n",
    "wine = wine.reset_index()\n",
    "df2 = df2.reset_index()\n",
    "df2 = df2.rename(columns = {'region': 'r2','country': 'c2', 'points': 'norm_points', \"price\": 'norm_price'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa2d206",
   "metadata": {},
   "source": [
    "### Normalizing Variables, Creating Wine Calc Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92f98b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_norm = ['norm_points','norm_price']\n",
    "df2[cols_to_norm] = df2[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f7bb7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = wine.merge(df2,on='winery', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9f1909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_wine_fin = wine\n",
    "best_wine_fin['wine_calc'] = (best_wine_fin['norm_points']-best_wine_fin['norm_price'])\n",
    "best_wine_fin = wine[['winery','region','country','points','norm_points','price','norm_price','wine_calc']]\n",
    "best_wine_fin = best_wine_fin.set_index('winery')\n",
    "#best_wine_fin['countyGroup'] = best_wine_fin['countyGroup'].replace({1.0: 'Napa County', 2.0: 'Sonoma County', 3.0 : 'Central Coast', 4.0: 'Northern California', 5.0 : 'Washington', 6.0 : 'Oregon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6c6b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: lightgreen' if v else '' for v in is_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec6e19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_min = s == s.min()\n",
    "    return ['background-color: red' if v else '' for v in is_min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9391d953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_eb7eb_row0_col6{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_eb7eb_\" ><caption>Top Bang for Your Buck Wineries</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >region</th>        <th class=\"col_heading level0 col1\" >country</th>        <th class=\"col_heading level0 col2\" >points</th>        <th class=\"col_heading level0 col3\" >norm_points</th>        <th class=\"col_heading level0 col4\" >price</th>        <th class=\"col_heading level0 col5\" >norm_price</th>        <th class=\"col_heading level0 col6\" >wine_calc</th>    </tr>    <tr>        <th class=\"index_name level0\" >winery</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_eb7eb_level0_row0\" class=\"row_heading level0 row0\" >Julien Schaal</th>\n",
       "                        <td id=\"T_eb7eb_row0_col0\" class=\"data row0 col0\" >Alsace</td>\n",
       "                        <td id=\"T_eb7eb_row0_col1\" class=\"data row0 col1\" >France</td>\n",
       "                        <td id=\"T_eb7eb_row0_col2\" class=\"data row0 col2\" >94.750000</td>\n",
       "                        <td id=\"T_eb7eb_row0_col3\" class=\"data row0 col3\" >0.819444</td>\n",
       "                        <td id=\"T_eb7eb_row0_col4\" class=\"data row0 col4\" >32.500000</td>\n",
       "                        <td id=\"T_eb7eb_row0_col5\" class=\"data row0 col5\" >0.202128</td>\n",
       "                        <td id=\"T_eb7eb_row0_col6\" class=\"data row0 col6\" >0.617317</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eb7eb_level0_row1\" class=\"row_heading level0 row1\" >Kevin White</th>\n",
       "                        <td id=\"T_eb7eb_row1_col0\" class=\"data row1 col0\" >Columbia Valley (WA)</td>\n",
       "                        <td id=\"T_eb7eb_row1_col1\" class=\"data row1 col1\" >US</td>\n",
       "                        <td id=\"T_eb7eb_row1_col2\" class=\"data row1 col2\" >94.000000</td>\n",
       "                        <td id=\"T_eb7eb_row1_col3\" class=\"data row1 col3\" >0.777778</td>\n",
       "                        <td id=\"T_eb7eb_row1_col4\" class=\"data row1 col4\" >28.000000</td>\n",
       "                        <td id=\"T_eb7eb_row1_col5\" class=\"data row1 col5\" >0.170213</td>\n",
       "                        <td id=\"T_eb7eb_row1_col6\" class=\"data row1 col6\" >0.607565</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eb7eb_level0_row2\" class=\"row_heading level0 row2\" >Philippe-Lorraine</th>\n",
       "                        <td id=\"T_eb7eb_row2_col0\" class=\"data row2 col0\" >Napa Valley</td>\n",
       "                        <td id=\"T_eb7eb_row2_col1\" class=\"data row2 col1\" >US</td>\n",
       "                        <td id=\"T_eb7eb_row2_col2\" class=\"data row2 col2\" >92.333333</td>\n",
       "                        <td id=\"T_eb7eb_row2_col3\" class=\"data row2 col3\" >0.685185</td>\n",
       "                        <td id=\"T_eb7eb_row2_col4\" class=\"data row2 col4\" >21.666667</td>\n",
       "                        <td id=\"T_eb7eb_row2_col5\" class=\"data row2 col5\" >0.125296</td>\n",
       "                        <td id=\"T_eb7eb_row2_col6\" class=\"data row2 col6\" >0.559890</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eb7eb_level0_row3\" class=\"row_heading level0 row3\" >Proteus</th>\n",
       "                        <td id=\"T_eb7eb_row3_col0\" class=\"data row3 col0\" >Willamette Valley</td>\n",
       "                        <td id=\"T_eb7eb_row3_col1\" class=\"data row3 col1\" >US</td>\n",
       "                        <td id=\"T_eb7eb_row3_col2\" class=\"data row3 col2\" >93.000000</td>\n",
       "                        <td id=\"T_eb7eb_row3_col3\" class=\"data row3 col3\" >0.722222</td>\n",
       "                        <td id=\"T_eb7eb_row3_col4\" class=\"data row3 col4\" >28.000000</td>\n",
       "                        <td id=\"T_eb7eb_row3_col5\" class=\"data row3 col5\" >0.170213</td>\n",
       "                        <td id=\"T_eb7eb_row3_col6\" class=\"data row3 col6\" >0.552009</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eb7eb_level0_row4\" class=\"row_heading level0 row4\" >Bestheim</th>\n",
       "                        <td id=\"T_eb7eb_row4_col0\" class=\"data row4 col0\" >Alsace</td>\n",
       "                        <td id=\"T_eb7eb_row4_col1\" class=\"data row4 col1\" >France</td>\n",
       "                        <td id=\"T_eb7eb_row4_col2\" class=\"data row4 col2\" >92.500000</td>\n",
       "                        <td id=\"T_eb7eb_row4_col3\" class=\"data row4 col3\" >0.694444</td>\n",
       "                        <td id=\"T_eb7eb_row4_col4\" class=\"data row4 col4\" >25.000000</td>\n",
       "                        <td id=\"T_eb7eb_row4_col5\" class=\"data row4 col5\" >0.148936</td>\n",
       "                        <td id=\"T_eb7eb_row4_col6\" class=\"data row4 col6\" >0.545508</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11d2de36a60>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_wine = best_wine_fin.sort_values(by='wine_calc', ascending=False).head(5)\n",
    "best_wine.style.set_caption(\"Top Bang for Your Buck Wineries\").apply(highlight_max, subset = best_wine.columns[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "927a4a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_6f6b8_row0_col6{\n",
       "            background-color:  red;\n",
       "        }</style><table id=\"T_6f6b8_\" ><caption>Worst Bang for Your Buck Wineries</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >region</th>        <th class=\"col_heading level0 col1\" >country</th>        <th class=\"col_heading level0 col2\" >points</th>        <th class=\"col_heading level0 col3\" >norm_points</th>        <th class=\"col_heading level0 col4\" >price</th>        <th class=\"col_heading level0 col5\" >norm_price</th>        <th class=\"col_heading level0 col6\" >wine_calc</th>    </tr>    <tr>        <th class=\"index_name level0\" >winery</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_6f6b8_level0_row0\" class=\"row_heading level0 row0\" >Better Half</th>\n",
       "                        <td id=\"T_6f6b8_row0_col0\" class=\"data row0 col0\" >Napa Valley</td>\n",
       "                        <td id=\"T_6f6b8_row0_col1\" class=\"data row0 col1\" >US</td>\n",
       "                        <td id=\"T_6f6b8_row0_col2\" class=\"data row0 col2\" >86.000000</td>\n",
       "                        <td id=\"T_6f6b8_row0_col3\" class=\"data row0 col3\" >0.333333</td>\n",
       "                        <td id=\"T_6f6b8_row0_col4\" class=\"data row0 col4\" >130.000000</td>\n",
       "                        <td id=\"T_6f6b8_row0_col5\" class=\"data row0 col5\" >0.893617</td>\n",
       "                        <td id=\"T_6f6b8_row0_col6\" class=\"data row0 col6\" >-0.560284</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6f6b8_level0_row1\" class=\"row_heading level0 row1\" >Concrete</th>\n",
       "                        <td id=\"T_6f6b8_row1_col0\" class=\"data row1 col0\" >Napa Valley</td>\n",
       "                        <td id=\"T_6f6b8_row1_col1\" class=\"data row1 col1\" >US</td>\n",
       "                        <td id=\"T_6f6b8_row1_col2\" class=\"data row1 col2\" >81.000000</td>\n",
       "                        <td id=\"T_6f6b8_row1_col3\" class=\"data row1 col3\" >0.055556</td>\n",
       "                        <td id=\"T_6f6b8_row1_col4\" class=\"data row1 col4\" >75.000000</td>\n",
       "                        <td id=\"T_6f6b8_row1_col5\" class=\"data row1 col5\" >0.503546</td>\n",
       "                        <td id=\"T_6f6b8_row1_col6\" class=\"data row1 col6\" >-0.447991</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6f6b8_level0_row2\" class=\"row_heading level0 row2\" >Horned Toad</th>\n",
       "                        <td id=\"T_6f6b8_row2_col0\" class=\"data row2 col0\" >Napa Valley</td>\n",
       "                        <td id=\"T_6f6b8_row2_col1\" class=\"data row2 col1\" >US</td>\n",
       "                        <td id=\"T_6f6b8_row2_col2\" class=\"data row2 col2\" >83.000000</td>\n",
       "                        <td id=\"T_6f6b8_row2_col3\" class=\"data row2 col3\" >0.166667</td>\n",
       "                        <td id=\"T_6f6b8_row2_col4\" class=\"data row2 col4\" >85.000000</td>\n",
       "                        <td id=\"T_6f6b8_row2_col5\" class=\"data row2 col5\" >0.574468</td>\n",
       "                        <td id=\"T_6f6b8_row2_col6\" class=\"data row2 col6\" >-0.407801</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6f6b8_level0_row3\" class=\"row_heading level0 row3\" >Calla Lily</th>\n",
       "                        <td id=\"T_6f6b8_row3_col0\" class=\"data row3 col0\" >Napa Valley</td>\n",
       "                        <td id=\"T_6f6b8_row3_col1\" class=\"data row3 col1\" >US</td>\n",
       "                        <td id=\"T_6f6b8_row3_col2\" class=\"data row3 col2\" >88.000000</td>\n",
       "                        <td id=\"T_6f6b8_row3_col3\" class=\"data row3 col3\" >0.444444</td>\n",
       "                        <td id=\"T_6f6b8_row3_col4\" class=\"data row3 col4\" >120.000000</td>\n",
       "                        <td id=\"T_6f6b8_row3_col5\" class=\"data row3 col5\" >0.822695</td>\n",
       "                        <td id=\"T_6f6b8_row3_col6\" class=\"data row3 col6\" >-0.378251</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6f6b8_level0_row4\" class=\"row_heading level0 row4\" >Pont de Chevalier</th>\n",
       "                        <td id=\"T_6f6b8_row4_col0\" class=\"data row4 col0\" >Napa Valley</td>\n",
       "                        <td id=\"T_6f6b8_row4_col1\" class=\"data row4 col1\" >US</td>\n",
       "                        <td id=\"T_6f6b8_row4_col2\" class=\"data row4 col2\" >90.000000</td>\n",
       "                        <td id=\"T_6f6b8_row4_col3\" class=\"data row4 col3\" >0.555556</td>\n",
       "                        <td id=\"T_6f6b8_row4_col4\" class=\"data row4 col4\" >135.000000</td>\n",
       "                        <td id=\"T_6f6b8_row4_col5\" class=\"data row4 col5\" >0.929078</td>\n",
       "                        <td id=\"T_6f6b8_row4_col6\" class=\"data row4 col6\" >-0.373522</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11d31e04cd0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_wine = best_wine_fin.sort_values(by='wine_calc', ascending=True).head(5)\n",
    "worst_wine.style.set_caption(\"Worst Bang for Your Buck Wineries\").apply(highlight_min, subset = best_wine.columns[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c873f6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
